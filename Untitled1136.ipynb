{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f7adac-fc2a-4972-a4d2-82300d76d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (15474, 8)\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/densenet/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m29084464/29084464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 1us/step\n",
      "Extracting CNN features (this may take ~40 mins)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting CNN features: 100%|███████████████████████████████████████████████████████████████████████████████████████| 15474/15474 [39:13<00:00,  6.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN features cached to: C:\\Users\\sagni\\Downloads\\House Pricing\\archive (1)\\cnn_features.npy\n",
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121, ResNet50\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess\n",
    "from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import xgboost as xgb\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Paths\n",
    "csv_path = r\"C:\\Users\\sagni\\Downloads\\House Pricing\\archive (1)\\socal2.csv\"\n",
    "img_folder = r\"C:\\Users\\sagni\\Downloads\\House Pricing\\archive (1)\\socal2\\socal_pics\"\n",
    "cache_file = r\"C:\\Users\\sagni\\Downloads\\House Pricing\\archive (1)\\cnn_features.npy\"\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(csv_path)\n",
    "print(f\"Data shape: {df.shape}\")\n",
    "\n",
    "# Drop missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "for col in df.select_dtypes(include=['object']).columns:\n",
    "    df[col] = LabelEncoder().fit_transform(df[col])\n",
    "\n",
    "# Target and features\n",
    "y = df['price']\n",
    "X_tabular = df.drop(['price', 'image_id'], axis=1)\n",
    "\n",
    "# Scale tabular data\n",
    "scaler = StandardScaler()\n",
    "X_tabular_scaled = scaler.fit_transform(X_tabular)\n",
    "\n",
    "# Select CNN model (DenseNet121 or ResNet50)\n",
    "cnn_model_name = \"DenseNet121\"  # Change to \"ResNet50\" for ResNet\n",
    "if cnn_model_name == \"DenseNet121\":\n",
    "    cnn_model = DenseNet121(weights='imagenet', include_top=False, pooling='avg')\n",
    "    preprocess_func = densenet_preprocess\n",
    "else:\n",
    "    cnn_model = ResNet50(weights='imagenet', include_top=False, pooling='avg')\n",
    "    preprocess_func = resnet_preprocess\n",
    "\n",
    "# Feature extraction function\n",
    "def extract_image_features(img_id):\n",
    "    img_filename = f\"{img_id}.jpg\"\n",
    "    img_path = os.path.join(img_folder, img_filename)\n",
    "    if not os.path.exists(img_path):\n",
    "        return np.zeros(cnn_model.output_shape[1])\n",
    "    img = image.load_img(img_path, target_size=(224, 224))  # ResNet/DenseNet input size\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = preprocess_func(img_array)\n",
    "    features = cnn_model.predict(img_array, verbose=0)\n",
    "    return features.flatten()\n",
    "\n",
    "# Check for cached features\n",
    "if os.path.exists(cache_file):\n",
    "    print(\"Loading cached CNN features...\")\n",
    "    image_features = np.load(cache_file)\n",
    "else:\n",
    "    print(\"Extracting CNN features (this may take ~40 mins)...\")\n",
    "    image_features = []\n",
    "    for img_id in tqdm(df['image_id'], desc=\"Extracting CNN features\"):\n",
    "        image_features.append(extract_image_features(img_id))\n",
    "    image_features = np.array(image_features)\n",
    "    np.save(cache_file, image_features)\n",
    "    print(\"CNN features cached to:\", cache_file)\n",
    "\n",
    "# Combine tabular and CNN features\n",
    "X_combined = np.hstack([X_tabular_scaled, image_features])\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# XGBoost with hyperparameter tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500],\n",
    "    'max_depth': [6, 8],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "xgb_model = xgb.XGBRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(xgb_model, param_grid, cv=3, scoring='r2', verbose=1, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best XGBoost Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Plot: Actual vs Predicted\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual vs Predicted House Prices')\n",
    "plt.show()\n",
    "\n",
    "# Plot: XGBoost Feature Importance\n",
    "xgb.plot_importance(best_model, max_num_features=10, height=0.5)\n",
    "plt.title('Top 10 XGBoost Feature Importances')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0411817-cf7a-47fb-9bbd-d5a418770894",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
